# ai_vision.py - v1.0 (AI-Powered Computer Vision)
# Nesne tespiti, Y√ºz tanƒ±ma, Hareket tespiti, QR/Barkod okuma

import logging
import time
import cv2
import numpy as np
from typing import Optional, List, Dict, Any, Tuple
from pathlib import Path
from dataclasses import dataclass
from collections import deque
import threading

logger = logging.getLogger(__name__)


# ============================================================================
# DETECTION RESULT DATA CLASS
# ============================================================================

@dataclass
class Detection:
    """Tespit edilen nesne/y√ºz/hareket bilgisi"""
    label: str
    confidence: float
    bbox: Tuple[int, int, int, int]  # (x, y, w, h)
    color: Tuple[int, int, int] = (0, 255, 0)
    metadata: Dict[str, Any] = None


# ============================================================================
# YOLO OBJECT DETECTOR (YOLOv8)
# ============================================================================

class YOLODetector:
    """YOLOv8 ile nesne tespiti"""

    def __init__(self, model_path: str = None, confidence: float = 0.5, iou: float = 0.4):
        self.model = None
        self.confidence = confidence
        self.iou = iou
        self.model_loaded = False

        try:
            from ultralytics import YOLO

            if model_path is None or not Path(model_path).exists():
                logger.info("YOLOv8 varsayƒ±lan model indiriliyor (yolov8n.pt - nano)...")
                model_path = 'yolov8n.pt'  # Otomatik indirir

            self.model = YOLO(model_path)
            self.model_loaded = True
            logger.info(f"‚úì YOLOv8 y√ºklendi: {model_path}")

        except ImportError:
            logger.warning("‚ö†Ô∏è ultralytics k√ºt√ºphanesi bulunamadƒ±. 'pip install ultralytics' √ßalƒ±≈ütƒ±rƒ±n.")
        except Exception as e:
            logger.error(f"YOLOv8 y√ºkleme hatasƒ±: {e}")

    def detect(self, frame: np.ndarray) -> List[Detection]:
        """Frame'de nesne tespiti yap"""
        if not self.model_loaded or frame is None:
            return []

        try:
            results = self.model.predict(
                frame,
                conf=self.confidence,
                iou=self.iou,
                verbose=False,
                device='cpu'  # RPi i√ßin CPU
            )

            detections = []

            for result in results:
                boxes = result.boxes

                for box in boxes:
                    # Koordinatlar
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    w = int(x2 - x1)
                    h = int(y2 - y1)

                    # Sƒ±nƒ±f ve g√ºven
                    conf = float(box.conf[0])
                    cls_id = int(box.cls[0])
                    label = result.names[cls_id]

                    detections.append(Detection(
                        label=label,
                        confidence=conf,
                        bbox=(int(x1), int(y1), w, h),
                        color=self._get_color_for_class(cls_id)
                    ))

            return detections

        except Exception as e:
            logger.error(f"YOLO detection hatasƒ±: {e}")
            return []

    def _get_color_for_class(self, cls_id: int) -> Tuple[int, int, int]:
        """Sƒ±nƒ±fa g√∂re renk d√∂nd√ºr"""
        colors = [
            (0, 255, 0),    # person - ye≈üil
            (255, 0, 0),    # bicycle - mavi
            (0, 0, 255),    # car - kƒ±rmƒ±zƒ±
            (255, 255, 0),  # motorcycle - cyan
            (255, 0, 255),  # airplane - magenta
        ]
        return colors[cls_id % len(colors)]


# ============================================================================
# FACE DETECTOR (OpenCV Haar Cascades)
# ============================================================================

class FaceDetector:
    """OpenCV Haar Cascades ile y√ºz tespiti"""

    def __init__(self):
        self.face_cascade = None
        self.eye_cascade = None
        self.model_loaded = False

        try:
            # Haar Cascade XML dosyalarƒ±
            cascade_path = cv2.data.haarcascades

            face_xml = Path(cascade_path) / 'haarcascade_frontalface_default.xml'
            eye_xml = Path(cascade_path) / 'haarcascade_eye.xml'

            if face_xml.exists():
                self.face_cascade = cv2.CascadeClassifier(str(face_xml))
                logger.info("‚úì Y√ºz tespit modeli y√ºklendi")
                self.model_loaded = True

            if eye_xml.exists():
                self.eye_cascade = cv2.CascadeClassifier(str(eye_xml))
                logger.info("‚úì G√∂z tespit modeli y√ºklendi")

        except Exception as e:
            logger.error(f"Face detector y√ºkleme hatasƒ±: {e}")

    def detect(self, frame: np.ndarray, detect_eyes: bool = False) -> List[Detection]:
        """Y√ºz tespiti yap"""
        if not self.model_loaded or frame is None:
            return []

        try:
            # Griye √ßevir
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

            # Y√ºzleri tespit et
            faces = self.face_cascade.detectMultiScale(
                gray,
                scaleFactor=1.1,
                minNeighbors=5,
                minSize=(30, 30)
            )

            detections = []

            for (x, y, w, h) in faces:
                detection = Detection(
                    label='face',
                    confidence=1.0,  # Haar cascades confidence vermez
                    bbox=(x, y, w, h),
                    color=(255, 0, 255),  # Magenta
                    metadata={'eyes': []}
                )

                # G√∂zleri tespit et (opsiyonel)
                if detect_eyes and self.eye_cascade:
                    roi_gray = gray[y:y+h, x:x+w]
                    eyes = self.eye_cascade.detectMultiScale(roi_gray)

                    for (ex, ey, ew, eh) in eyes:
                        detection.metadata['eyes'].append({
                            'bbox': (x + ex, y + ey, ew, eh)
                        })

                detections.append(detection)

            return detections

        except Exception as e:
            logger.error(f"Face detection hatasƒ±: {e}")
            return []


# ============================================================================
# MOTION DETECTOR (Frame Differencing)
# ============================================================================

class MotionDetector:
    """Hareket tespiti (frame diff + contour detection)"""

    def __init__(self, min_area: int = 500, threshold: int = 25):
        self.min_area = min_area
        self.threshold = threshold
        self.prev_frame = None
        self.motion_history = deque(maxlen=30)  # Son 30 frame

    def detect(self, frame: np.ndarray) -> Tuple[List[Detection], float]:
        """
        Hareket tespiti yap

        Returns:
            (detections, motion_percentage)
        """
        if frame is None:
            return [], 0.0

        try:
            # Griye √ßevir + blur
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            gray = cv2.GaussianBlur(gray, (21, 21), 0)

            # ƒ∞lk frame ise kaydet
            if self.prev_frame is None:
                self.prev_frame = gray
                return [], 0.0

            # Frame farkƒ± hesapla
            frame_delta = cv2.absdiff(self.prev_frame, gray)
            thresh = cv2.threshold(frame_delta, self.threshold, 255, cv2.THRESH_BINARY)[1]

            # Morfolojik i≈ülemler (g√ºr√ºlt√º temizleme)
            thresh = cv2.dilate(thresh, None, iterations=2)

            # Konturlarƒ± bul
            contours, _ = cv2.findContours(
                thresh.copy(),
                cv2.RETR_EXTERNAL,
                cv2.CHAIN_APPROX_SIMPLE
            )

            detections = []
            total_motion_area = 0

            for contour in contours:
                area = cv2.contourArea(contour)

                if area < self.min_area:
                    continue

                total_motion_area += area

                # Bounding box
                x, y, w, h = cv2.boundingRect(contour)

                detections.append(Detection(
                    label='motion',
                    confidence=min(area / 10000, 1.0),  # Alan bazlƒ± confidence
                    bbox=(x, y, w, h),
                    color=(0, 255, 255),  # Sarƒ±
                    metadata={'area': area}
                ))

            # Hareket y√ºzdesi
            frame_area = frame.shape[0] * frame.shape[1]
            motion_percentage = (total_motion_area / frame_area) * 100

            self.motion_history.append(motion_percentage)

            # Frame'i g√ºncelle
            self.prev_frame = gray

            return detections, motion_percentage

        except Exception as e:
            logger.error(f"Motion detection hatasƒ±: {e}")
            return [], 0.0

    def reset(self):
        """Hareket ge√ßmi≈üini sƒ±fƒ±rla"""
        self.prev_frame = None
        self.motion_history.clear()

    def get_average_motion(self) -> float:
        """Ortalama hareket y√ºzdesi"""
        if not self.motion_history:
            return 0.0
        return sum(self.motion_history) / len(self.motion_history)


# ============================================================================
# QR/BARCODE READER
# ============================================================================

class QRBarcodeReader:
    """QR ve Barkod okuma (pyzbar)"""

    def __init__(self):
        self.reader_loaded = False

        try:
            import pyzbar.pyzbar as pyzbar
            self.pyzbar = pyzbar
            self.reader_loaded = True
            logger.info("‚úì QR/Barkod okuyucu y√ºklendi")
        except ImportError:
            logger.warning("‚ö†Ô∏è pyzbar k√ºt√ºphanesi bulunamadƒ±. 'pip install pyzbar' √ßalƒ±≈ütƒ±rƒ±n.")

    def detect(self, frame: np.ndarray) -> List[Detection]:
        """QR/Barkod tespiti yap"""
        if not self.reader_loaded or frame is None:
            return []

        try:
            # Griye √ßevir
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

            # QR/Barkodlarƒ± tespit et
            decoded_objects = self.pyzbar.decode(gray)

            detections = []

            for obj in decoded_objects:
                # Koordinatlar
                x, y, w, h = obj.rect

                # Data
                data = obj.data.decode('utf-8')
                obj_type = obj.type

                detections.append(Detection(
                    label=f'{obj_type}',
                    confidence=1.0,
                    bbox=(x, y, w, h),
                    color=(0, 165, 255),  # Turuncu
                    metadata={'data': data, 'type': obj_type}
                ))

            return detections

        except Exception as e:
            logger.error(f"QR/Barcode detection hatasƒ±: {e}")
            return []


# ============================================================================
# EDGE DETECTOR (Canny)
# ============================================================================

class EdgeDetector:
    """Kenar tespiti ve kontur analizi"""

    def __init__(self, low_threshold: int = 50, high_threshold: int = 150):
        self.low_threshold = low_threshold
        self.high_threshold = high_threshold

    def detect(self, frame: np.ndarray, min_area: int = 1000) -> Tuple[np.ndarray, List[Detection]]:
        """
        Kenar tespiti yap

        Returns:
            (edge_frame, contour_detections)
        """
        if frame is None:
            return None, []

        try:
            # Griye √ßevir
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

            # Blur
            blurred = cv2.GaussianBlur(gray, (5, 5), 0)

            # Canny edge detection
            edges = cv2.Canny(blurred, self.low_threshold, self.high_threshold)

            # Konturlarƒ± bul
            contours, _ = cv2.findContours(
                edges.copy(),
                cv2.RETR_EXTERNAL,
                cv2.CHAIN_APPROX_SIMPLE
            )

            detections = []

            for contour in contours:
                area = cv2.contourArea(contour)

                if area < min_area:
                    continue

                # Bounding box
                x, y, w, h = cv2.boundingRect(contour)

                # Perimeter ve circularity
                perimeter = cv2.arcLength(contour, True)
                circularity = 4 * np.pi * area / (perimeter ** 2) if perimeter > 0 else 0

                detections.append(Detection(
                    label='contour',
                    confidence=min(area / 50000, 1.0),
                    bbox=(x, y, w, h),
                    color=(255, 165, 0),  # Turuncu
                    metadata={
                        'area': area,
                        'perimeter': perimeter,
                        'circularity': circularity
                    }
                ))

            # Edge frame'i renkli yap (g√∂rselle≈ütirme i√ßin)
            edge_colored = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)

            return edge_colored, detections

        except Exception as e:
            logger.error(f"Edge detection hatasƒ±: {e}")
            return frame, []


# ============================================================================
# UNIFIED AI VISION MANAGER
# ============================================================================

class AIVisionManager:
    """T√ºm AI/CV mod√ºllerini birle≈ütiren y√∂netici"""

    def __init__(self, config: Dict[str, Any] = None):
        self.config = config or {}

        # Detectorler
        self.yolo = None
        self.face_detector = None
        self.motion_detector = None
        self.qr_reader = None
        self.edge_detector = None

        # Durum
        self.enabled_modules = {
            'yolo': False,
            'face': False,
            'motion': False,
            'qr': False,
            'edges': False
        }

        # Thread safety
        self.lock = threading.Lock()

        logger.info("AI Vision Manager ba≈ülatƒ±ldƒ±")

    def initialize_module(self, module_name: str, **kwargs) -> bool:
        """Mod√ºl ba≈ülat"""
        with self.lock:
            try:
                if module_name == 'yolo':
                    self.yolo = YOLODetector(**kwargs)
                    self.enabled_modules['yolo'] = self.yolo.model_loaded
                    return self.enabled_modules['yolo']

                elif module_name == 'face':
                    self.face_detector = FaceDetector()
                    self.enabled_modules['face'] = self.face_detector.model_loaded
                    return self.enabled_modules['face']

                elif module_name == 'motion':
                    self.motion_detector = MotionDetector(**kwargs)
                    self.enabled_modules['motion'] = True
                    return True

                elif module_name == 'qr':
                    self.qr_reader = QRBarcodeReader()
                    self.enabled_modules['qr'] = self.qr_reader.reader_loaded
                    return self.enabled_modules['qr']

                elif module_name == 'edges':
                    self.edge_detector = EdgeDetector(**kwargs)
                    self.enabled_modules['edges'] = True
                    return True

                else:
                    logger.warning(f"Bilinmeyen mod√ºl: {module_name}")
                    return False

            except Exception as e:
                logger.error(f"Mod√ºl ba≈ülatma hatasƒ± ({module_name}): {e}")
                return False

    def process_frame(self,
                      frame: np.ndarray,
                      modules: List[str] = None,
                      draw_results: bool = True) -> Tuple[np.ndarray, Dict[str, Any]]:
        """
        Frame'i i≈üle (t√ºm aktif mod√ºller)

        Args:
            frame: ƒ∞≈ülenecek frame
            modules: Kullanƒ±lacak mod√ºller (None ise t√ºm√º)
            draw_results: Sonu√ßlarƒ± frame √ºzerine √ßiz

        Returns:
            (processed_frame, results_dict)
        """
        if frame is None:
            return None, {}

        if modules is None:
            modules = [k for k, v in self.enabled_modules.items() if v]

        results = {
            'detections': [],
            'motion_percentage': 0.0,
            'edge_frame': None,
            'stats': {}
        }

        output_frame = frame.copy() if draw_results else frame

        # YOLO
        if 'yolo' in modules and self.yolo:
            yolo_detections = self.yolo.detect(frame)
            results['detections'].extend(yolo_detections)
            results['stats']['yolo_objects'] = len(yolo_detections)

        # Face Detection
        if 'face' in modules and self.face_detector:
            face_detections = self.face_detector.detect(frame, detect_eyes=True)
            results['detections'].extend(face_detections)
            results['stats']['faces'] = len(face_detections)

        # Motion Detection
        if 'motion' in modules and self.motion_detector:
            motion_detections, motion_pct = self.motion_detector.detect(frame)
            results['detections'].extend(motion_detections)
            results['motion_percentage'] = motion_pct
            results['stats']['motion_regions'] = len(motion_detections)

        # QR/Barcode
        if 'qr' in modules and self.qr_reader:
            qr_detections = self.qr_reader.detect(frame)
            results['detections'].extend(qr_detections)
            results['stats']['qr_codes'] = len(qr_detections)

        # Edge Detection
        if 'edges' in modules and self.edge_detector:
            edge_frame, edge_detections = self.edge_detector.detect(frame)
            results['edge_frame'] = edge_frame
            results['detections'].extend(edge_detections)
            results['stats']['contours'] = len(edge_detections)

        # Sonu√ßlarƒ± √ßiz
        if draw_results:
            output_frame = self._draw_detections(output_frame, results['detections'])

        return output_frame, results

    def _draw_detections(self, frame: np.ndarray, detections: List[Detection]) -> np.ndarray:
        """Tespitleri frame √ºzerine √ßiz"""
        for det in detections:
            x, y, w, h = det.bbox

            # Bounding box
            cv2.rectangle(frame, (x, y), (x + w, y + h), det.color, 2)

            # Label
            label_text = f"{det.label}: {det.confidence:.2f}"

            # Arka plan (okunabilirlik i√ßin)
            (text_w, text_h), _ = cv2.getTextSize(
                label_text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1
            )
            cv2.rectangle(
                frame,
                (x, y - text_h - 8),
                (x + text_w + 8, y),
                det.color,
                -1
            )

            # Text
            cv2.putText(
                frame,
                label_text,
                (x + 4, y - 4),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.5,
                (255, 255, 255),
                1
            )

            # Metadata (QR data, vb.)
            if det.metadata and 'data' in det.metadata:
                data_text = det.metadata['data'][:30]  # ƒ∞lk 30 karakter
                cv2.putText(
                    frame,
                    data_text,
                    (x, y + h + 20),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.4,
                    (0, 255, 255),
                    1
                )

        return frame

    def get_status(self) -> Dict[str, Any]:
        """Mod√ºl durumlarƒ±nƒ± al"""
        return {
            'enabled_modules': self.enabled_modules.copy(),
            'motion_avg': self.motion_detector.get_average_motion() if self.motion_detector else 0.0
        }


# ============================================================================
# GLOBAL INSTANCE
# ============================================================================

ai_vision_manager = AIVisionManager()


# Export
__all__ = [
    'AIVisionManager',
    'ai_vision_manager',
    'Detection',
    'YOLODetector',
    'FaceDetector',
    'MotionDetector',
    'QRBarcodeReader',
    'EdgeDetector'
]


if __name__ == "__main__":
    # Test modu
    logging.basicConfig(level=logging.INFO)

    print("üß™ AI Vision Manager Test")
    print("=" * 60)

    manager = AIVisionManager()

    # Mod√ºlleri ba≈ülat
    print("\nüì¶ Mod√ºller ba≈ülatƒ±lƒ±yor...")
    manager.initialize_module('yolo')
    manager.initialize_module('face')
    manager.initialize_module('motion')
    manager.initialize_module('qr')
    manager.initialize_module('edges')

    status = manager.get_status()
    print(f"\n‚úì Durum: {status}")

    # Test frame
    test_frame = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)

    print("\nüîç Test frame i≈üleniyor...")
    processed, results = manager.process_frame(test_frame, draw_results=True)

    print(f"\nüìä Sonu√ßlar:")
    print(f"  Tespit sayƒ±sƒ±: {len(results['detections'])}")
    print(f"  ƒ∞statistikler: {results['stats']}")
    print(f"  Hareket: {results['motion_percentage']:.2f}%")

    print("\n‚úì Test tamamlandƒ±!")